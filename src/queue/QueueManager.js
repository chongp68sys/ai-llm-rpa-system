import { Queue, Worker, QueueEvents } from 'bullmq';
import { redisConfig, QUEUE_NAMES, JOB_OPTIONS } from './config.js';
import ExecutionContext from '../backend/ExecutionContext.js';

class QueueManager {
  constructor() {
    this.queues = new Map();
    this.workers = new Map();
    this.queueEvents = new Map();
    this.isInitialized = false;
  }

  async initialize() {
    if (this.isInitialized) {
      console.log('Queue manager already initialized');
      return;
    }

    try {
      // Create queues
      for (const queueName of Object.values(QUEUE_NAMES)) {
        const queue = new Queue(queueName, redisConfig);
        this.queues.set(queueName, queue);

        // Create queue events for monitoring
        const queueEvents = new QueueEvents(queueName, redisConfig);
        this.queueEvents.set(queueName, queueEvents);
        
        // Set up event listeners
        this.setupQueueEventListeners(queueName, queueEvents);
      }

      // Create workers
      this.createWorkers();

      this.isInitialized = true;
      console.log('‚úÖ Queue manager initialized successfully');
    } catch (error) {
      console.error('‚ùå Failed to initialize queue manager:', error);
      throw error;
    }
  }

  createWorkers() {
    // Workflow execution worker
    const workflowWorker = new Worker(
      QUEUE_NAMES.WORKFLOW_EXECUTION,
      async (job) => {
        console.log(`üöÄ Processing workflow execution job: ${job.id}`);
        const { workflowId, executionId, context } = job.data;
        
        try {
          const executionContext = new ExecutionContext(workflowId, executionId);
          
          // Set context variables if provided
          if (context) {
            Object.entries(context).forEach(([key, value]) => {
              executionContext.setVariable(key, value);
            });
          }
          
          // For now, just return success since we don't have the full execution engine implemented
          const result = {
            status: 'completed',
            executionId,
            workflowId,
            completedAt: new Date().toISOString()
          };
          
          console.log(`‚úÖ Workflow execution ${executionId} completed successfully`);
          return result;
        } catch (error) {
          console.error(`‚ùå Workflow execution ${executionId} failed:`, error);
          throw error;
        }
      },
      {
        ...redisConfig,
        concurrency: 3, // Process up to 3 workflows simultaneously
      }
    );

    // Email sending worker
    const emailWorker = new Worker(
      QUEUE_NAMES.EMAIL_SENDING,
      async (job) => {
        console.log(`üìß Processing email job: ${job.id}`);
        const { to, subject, content, nodeId, executionId } = job.data;
        
        try {
          // Import email processor dynamically to avoid circular dependencies
          const { EmailProcessor } = await import('../backend/processors/EmailProcessor.js');
          const emailProcessor = new EmailProcessor();
          
          const result = await emailProcessor.process({
            recipients: to,
            subject,
            content,
            nodeId,
            executionId,
          });
          
          console.log(`‚úÖ Email sent successfully to ${to}`);
          return result;
        } catch (error) {
          console.error(`‚ùå Email sending failed:`, error);
          throw error;
        }
      },
      {
        ...redisConfig,
        concurrency: 5, // Process up to 5 emails simultaneously
      }
    );

    // Webhook processing worker
    const webhookWorker = new Worker(
      QUEUE_NAMES.WEBHOOK_PROCESSING,
      async (job) => {
        console.log(`üîó Processing webhook job: ${job.id}`);
        const { url, method, payload, headers, nodeId, executionId } = job.data;
        
        try {
          // Import webhook processor dynamically
          const { WebhookProcessor } = await import('../backend/processors/WebhookProcessor.js');
          const webhookProcessor = new WebhookProcessor();
          
          const result = await webhookProcessor.process({
            url,
            method,
            payload,
            headers,
            nodeId,
            executionId,
          });
          
          console.log(`‚úÖ Webhook processed successfully: ${url}`);
          return result;
        } catch (error) {
          console.error(`‚ùå Webhook processing failed:`, error);
          throw error;
        }
      },
      {
        ...redisConfig,
        concurrency: 10, // Process up to 10 webhooks simultaneously
      }
    );

    // File processing worker
    const fileWorker = new Worker(
      QUEUE_NAMES.FILE_PROCESSING,
      async (job) => {
        console.log(`üìÅ Processing file job: ${job.id}`);
        const { filePath, operation, nodeId, executionId } = job.data;
        
        try {
          // Import file processor dynamically
          const { FileProcessor } = await import('../backend/processors/FileProcessor.js');
          const fileProcessor = new FileProcessor();
          
          const result = await fileProcessor.process({
            filePath,
            operation,
            nodeId,
            executionId,
          });
          
          console.log(`‚úÖ File processed successfully: ${filePath}`);
          return result;
        } catch (error) {
          console.error(`‚ùå File processing failed:`, error);
          throw error;
        }
      },
      {
        ...redisConfig,
        concurrency: 3, // Process up to 3 files simultaneously
      }
    );

    // LLM processing worker
    const llmWorker = new Worker(
      QUEUE_NAMES.LLM_PROCESSING,
      async (job) => {
        console.log(`ü§ñ Processing LLM job: ${job.id}`);
        const { provider, prompt, model, nodeId, executionId } = job.data;
        
        try {
          // Import LLM processor dynamically
          const { LLMProcessor } = await import('../backend/processors/LLMProcessor.js');
          const llmProcessor = new LLMProcessor();
          
          const result = await llmProcessor.process({
            provider,
            prompt,
            model,
            nodeId,
            executionId,
          });
          
          console.log(`‚úÖ LLM processing completed successfully`);
          return result;
        } catch (error) {
          console.error(`‚ùå LLM processing failed:`, error);
          throw error;
        }
      },
      {
        ...redisConfig,
        concurrency: 2, // Process up to 2 LLM requests simultaneously
      }
    );

    // Store workers
    this.workers.set(QUEUE_NAMES.WORKFLOW_EXECUTION, workflowWorker);
    this.workers.set(QUEUE_NAMES.EMAIL_SENDING, emailWorker);
    this.workers.set(QUEUE_NAMES.WEBHOOK_PROCESSING, webhookWorker);
    this.workers.set(QUEUE_NAMES.FILE_PROCESSING, fileWorker);
    this.workers.set(QUEUE_NAMES.LLM_PROCESSING, llmWorker);

    console.log('‚úÖ All queue workers created successfully');
  }

  setupQueueEventListeners(queueName, queueEvents) {
    queueEvents.on('completed', ({ jobId }) => {
      console.log(`‚úÖ Job ${jobId} in queue ${queueName} completed`);
    });

    queueEvents.on('failed', ({ jobId, failedReason }) => {
      console.error(`‚ùå Job ${jobId} in queue ${queueName} failed:`, failedReason);
    });

    queueEvents.on('progress', ({ jobId, data }) => {
      console.log(`‚è≥ Job ${jobId} in queue ${queueName} progress: ${data}%`);
    });
  }

  // Public methods for adding jobs to queues
  async addWorkflowExecution(workflowId, executionId, context, options = {}) {
    const queue = this.queues.get(QUEUE_NAMES.WORKFLOW_EXECUTION);
    if (!queue) throw new Error('Workflow execution queue not initialized');
    
    return await queue.add(
      'execute-workflow',
      { workflowId, executionId, context },
      { ...JOB_OPTIONS[QUEUE_NAMES.WORKFLOW_EXECUTION], ...options }
    );
  }

  async addEmailJob(emailData, options = {}) {
    const queue = this.queues.get(QUEUE_NAMES.EMAIL_SENDING);
    if (!queue) throw new Error('Email queue not initialized');
    
    return await queue.add(
      'send-email',
      emailData,
      { ...JOB_OPTIONS[QUEUE_NAMES.EMAIL_SENDING], ...options }
    );
  }

  async addWebhookJob(webhookData, options = {}) {
    const queue = this.queues.get(QUEUE_NAMES.WEBHOOK_PROCESSING);
    if (!queue) throw new Error('Webhook queue not initialized');
    
    return await queue.add(
      'process-webhook',
      webhookData,
      { ...JOB_OPTIONS[QUEUE_NAMES.WEBHOOK_PROCESSING], ...options }
    );
  }

  async addFileJob(fileData, options = {}) {
    const queue = this.queues.get(QUEUE_NAMES.FILE_PROCESSING);
    if (!queue) throw new Error('File processing queue not initialized');
    
    return await queue.add(
      'process-file',
      fileData,
      { ...JOB_OPTIONS[QUEUE_NAMES.FILE_PROCESSING], ...options }
    );
  }

  async addLLMJob(llmData, options = {}) {
    const queue = this.queues.get(QUEUE_NAMES.LLM_PROCESSING);
    if (!queue) throw new Error('LLM processing queue not initialized');
    
    return await queue.add(
      'process-llm',
      llmData,
      { ...JOB_OPTIONS[QUEUE_NAMES.LLM_PROCESSING], ...options }
    );
  }

  // Queue management methods
  async getQueueStats(queueName) {
    const queue = this.queues.get(queueName);
    if (!queue) throw new Error(`Queue ${queueName} not found`);
    
    return {
      waiting: await queue.getWaiting(),
      active: await queue.getActive(),
      completed: await queue.getCompleted(),
      failed: await queue.getFailed(),
      delayed: await queue.getDelayed(),
    };
  }

  async pauseQueue(queueName) {
    const queue = this.queues.get(queueName);
    if (!queue) throw new Error(`Queue ${queueName} not found`);
    
    await queue.pause();
    console.log(`‚è∏Ô∏è Queue ${queueName} paused`);
  }

  async resumeQueue(queueName) {
    const queue = this.queues.get(queueName);
    if (!queue) throw new Error(`Queue ${queueName} not found`);
    
    await queue.resume();
    console.log(`‚ñ∂Ô∏è Queue ${queueName} resumed`);
  }

  async clearQueue(queueName) {
    const queue = this.queues.get(queueName);
    if (!queue) throw new Error(`Queue ${queueName} not found`);
    
    await queue.obliterate({ force: true });
    console.log(`üóëÔ∏è Queue ${queueName} cleared`);
  }

  // Health check
  async healthCheck() {
    try {
      // Check if queues are initialized
      if (this.queues.size === 0) {
        throw new Error('No queues initialized');
      }

      // Test Redis connection by trying to get queue info
      const firstQueue = this.queues.values().next().value;
      // This will test the Redis connection indirectly
      await firstQueue.getWaiting();
      
      return { status: 'healthy', timestamp: new Date().toISOString() };
    } catch (error) {
      return { status: 'unhealthy', error: error.message, timestamp: new Date().toISOString() };
    }
  }

  // Graceful shutdown
  async close() {
    console.log('üîÑ Shutting down queue manager...');
    
    // Close all workers
    for (const [queueName, worker] of this.workers) {
      console.log(`Closing worker for ${queueName}`);
      await worker.close();
    }
    
    // Close all queue events
    for (const [queueName, queueEvents] of this.queueEvents) {
      console.log(`Closing queue events for ${queueName}`);
      await queueEvents.close();
    }
    
    // Close all queues
    for (const [queueName, queue] of this.queues) {
      console.log(`Closing queue ${queueName}`);
      await queue.close();
    }
    
    this.isInitialized = false;
    console.log('‚úÖ Queue manager shut down successfully');
  }
}

// Export singleton instance
export const queueManager = new QueueManager();